{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BERT\n",
        "**BERT**, or <u>Bidirectional Encoder Representations from Transformers</u>, is a powerful natural language processing (NLP) technique developed by researchers at Google. It's based on the *Transformer architecture* and is designed to understand the context of words in a sentence by considering the words that come before and after them. Unlike previous models that processed words in a left-to-right or right-to-left manner, BERT can take into account the entire context of a word by processing it bidirectionally.\n",
        "\n",
        "BERT has achieved state-of-the-art results in various NLP tasks such as question answering, sentiment analysis, and language translation. It's pre-trained on large corpora of text data and can then be fine-tuned on specific tasks with smaller, task-specific datasets. This pre-training followed by fine-tuning approach has made BERT highly effective in a wide range of NLP applications."
      ],
      "metadata": {
        "id": "v2j11hVA-ilD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [Text preprocessing for BERT + SavedModel implementation of the encoder API](https://www.kaggle.com/models/tensorflow/bert/tensorFlow2/en-uncased-l-12-h-768-a-12)"
      ],
      "metadata": {
        "id": "GJ3C5bN9FPDJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tensorflow2 BERT encoder model : **bert/tensorFlow2/en-uncased-l-12-h-768-a-12**\n",
        "\n",
        "Here, we are using \"BERT Base\" model having configuartion like\n",
        "\n",
        "**l-12-h-768-a-12**\n",
        "* l - 12 : layer = 12\n",
        "* h-768 : hidden state 768\n",
        "* a - 12 : attention 12"
      ],
      "metadata": {
        "id": "1g-H3701YYgL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rg0LIXJb86cZ"
      },
      "outputs": [],
      "source": []
    }
  ]
}