{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# [Quantization aware training in Keras example](https://www.tensorflow.org/model_optimization/guide/quantization/training_example)"
      ],
      "metadata": {
        "id": "CUXPseN0dPwA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "In this tutorial, you will:\n",
        "\n",
        "1. Train a keras model for MNIST from scratch.\n",
        "2. Fine tune the model by applying the quantization aware training API, see the accuracy, and export a quantization aware model.\n",
        "3. Use the model to create an actually quantized model for the TFLite backend.\n",
        "4. See the persistence of accuracy in TFLite and a 4x smaller model. To see the latency benefits on mobile, try out the TFLite examples in the [TFLite app repository](https://www.tensorflow.org/lite/models)"
      ],
      "metadata": {
        "id": "NvxJCTaAdgNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow\n",
        "!pip install -q tensorflow-model-optimization"
      ],
      "metadata": {
        "id": "TqSTrZmueQJ0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}