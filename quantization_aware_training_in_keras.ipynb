{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# [Quantization aware training in Keras example](https://www.tensorflow.org/model_optimization/guide/quantization/training_example)"
      ],
      "metadata": {
        "id": "CUXPseN0dPwA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "In this tutorial, you will:\n",
        "\n",
        "1. Train a keras model for MNIST from scratch.\n",
        "2. Fine tune the model by applying the quantization aware training API, see the accuracy, and export a quantization aware model.\n",
        "3. Use the model to create an actually quantized model for the TFLite backend.\n",
        "4. See the persistence of accuracy in TFLite and a 4x smaller model. To see the latency benefits on mobile, try out the TFLite examples in the [TFLite app repository](https://www.tensorflow.org/lite/models)"
      ],
      "metadata": {
        "id": "NvxJCTaAdgNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow\n",
        "!pip install -q tensorflow-model-optimization"
      ],
      "metadata": {
        "id": "TqSTrZmueQJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89ab2beb-32cf-498b-ce07-a467bf4390fd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/242.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "6xyY2BpIfGTI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a model for MNIST without quantization aware training\n",
        "\n",
        "The **MNIST** database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems. The database is also widely used for training and testing in the field of machine learning."
      ],
      "metadata": {
        "id": "LqM_8QVU1Q8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load MNIST Dataset"
      ],
      "metadata": {
        "id": "PJ0cZf3RtJSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "id": "3ldH3Sl9tHjY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed211b6a-fa72-43de-ab6d-115656407c27"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalize the dataset"
      ],
      "metadata": {
        "id": "QGYnYHQ-4RPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "TMkmYnwA4a3L"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the model architecture"
      ],
      "metadata": {
        "id": "34LdKWG161I1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
        "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(10)\n",
        "])"
      ],
      "metadata": {
        "id": "VwOHpQkJ66A4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a3064c7-525e-48a4-df6f-7717f75bce74"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the digit classification model"
      ],
      "metadata": {
        "id": "nzE_pjVABGKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ygeTJ2POBJ4a"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=1,\n",
        "  validation_split=0.1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkgjS4U7bUi7",
        "outputId": "a9903922-259a-4e43-ff39-782fec694750"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.8429 - loss: 0.5682 - val_accuracy: 0.9658 - val_loss: 0.1281\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f1fb5fec810>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone and fine-tune pre-trained model with quantization aware training\n",
        "### Define the model\n",
        "\n",
        "You will apply quantization aware training to the whole model and see this in the model summary. All layers are now prefixed by \"quant\".\n",
        "\n",
        "Note that the resulting model is quantization aware but not quantized (e.g. the weights are float32 instead of int8). The sections after show how to create a quantized model from the quantization aware one.\n",
        "\n",
        "In the [comprehensive guide](https://www.tensorflow.org/model_optimization/guide/quantization/training_comprehensive_guide.md), you can see how to quantize some layers for model accuracy improvements."
      ],
      "metadata": {
        "id": "6jg9HYh1b5HN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "from tensorflow_model_optimization.python.core.keras.compat import keras # Import keras from tfmot\n",
        "\n",
        "# Instead of directly applying quantize_model, recreate the model structure\n",
        "def create_quantizable_model():\n",
        "    model = keras.Sequential([ # Use keras imported from tfmot\n",
        "        keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "        keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "        keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
        "        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(10)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Create a new model instance\n",
        "quantizable_model = create_quantizable_model()\n",
        "\n",
        "# Now apply quantize_model\n",
        "q_aware_model = tfmot.quantization.keras.quantize_model(quantizable_model)\n",
        "\n",
        "# Compile the quantized model\n",
        "q_aware_model.compile(optimizer='adam',\n",
        "                      loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "q_aware_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxcmFM1fg1BV",
        "outputId": "2a9f45f2-37ee-4002-d45b-be3de5a2bcde"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " quantize_layer (QuantizeLa  (None, 28, 28)            3         \n",
            " yer)                                                            \n",
            "                                                                 \n",
            " quant_reshape (QuantizeWra  (None, 28, 28, 1)         1         \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_conv2d (QuantizeWrap  (None, 26, 26, 12)        147       \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_max_pooling2d (Quant  (None, 13, 13, 12)        1         \n",
            " izeWrapperV2)                                                   \n",
            "                                                                 \n",
            " quant_flatten (QuantizeWra  (None, 2028)              1         \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_dense (QuantizeWrapp  (None, 10)                20295     \n",
            " erV2)                                                           \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20448 (79.88 KB)\n",
            "Trainable params: 20410 (79.73 KB)\n",
            "Non-trainable params: 38 (152.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and evaluate the model against baseline\n",
        "\n",
        "To demonstrate fine tuning after training the model for just an epoch, fine tune with quantization aware training on a subset of the training data.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v6jj1VLpipGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_subset = train_images[0:1000] # out of 60000\n",
        "train_labels_subset = train_labels[0:1000]\n",
        "\n",
        "q_aware_model.fit(train_images_subset, train_labels_subset,\n",
        "                  batch_size=500, epochs=1, validation_split=0.1)"
      ],
      "metadata": {
        "id": "8-EruETkCtuI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc67a9c5-4781-45fc-cdd1-e67a332295b9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 8s 1s/step - loss: 2.3006 - accuracy: 0.1144 - val_loss: 2.2359 - val_accuracy: 0.2000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7f1fb1f32510>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, baseline_model_accuracy = model.evaluate(\n",
        "    test_images, test_labels, verbose=0)\n",
        "\n",
        "_, q_aware_model_accuracy = q_aware_model.evaluate(\n",
        "   test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)\n",
        "print('Quant test accuracy:', q_aware_model_accuracy)"
      ],
      "metadata": {
        "id": "DhYtbk9Qf_0T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bb6b13c-6840-4151-fabe-9edac786bff3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline test accuracy: 0.9591000080108643\n",
            "Quant test accuracy: 0.22439999878406525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create quantized model for TFLite backend\n",
        "\n",
        "After this, you have an actually quantized model with int8 weights and uint8 activations."
      ],
      "metadata": {
        "id": "8grwBo47n3T0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "quantized_tflite_model = converter.convert()"
      ],
      "metadata": {
        "id": "Do5bysZkp1aq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ca6afd1-e0f5-4db7-bb8c-aaeecd035fff"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/convert.py:983: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## See persistence of accuracy from TF to TFLite\n",
        "\n",
        "Define a helper function to evaluate the TF Lite model on the test dataset."
      ],
      "metadata": {
        "id": "pCXcA781UB3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def evaluate_model(interpreter):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "   # Run predictions on every image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for i, test_image in enumerate(test_images):\n",
        "    if i % 1000 == 0:\n",
        "      print('Evaluated on {n} results so far.'.format(n=i))\n",
        "      # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  print('\\n')\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  prediction_digits = np.array(prediction_digits)\n",
        "  accuracy = (prediction_digits == test_labels).mean()\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "gqp1Qt82UbFI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "evaluate the quantized model and see that the accuracy from TensorFlow persists to the TFLite backend."
      ],
      "metadata": {
        "id": "QB4sGUqb08Hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "test_accuracy = evaluate_model(interpreter)\n",
        "\n",
        "print('Quant TFLite test_accuracy:', test_accuracy)\n",
        "print('Quant TF test accuracy:', q_aware_model_accuracy)"
      ],
      "metadata": {
        "id": "ZZQXSgT9FD8S"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}